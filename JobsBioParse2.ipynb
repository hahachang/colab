{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hahachang/colab/blob/main/JobsBioParse2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VIfGeRwAakxk"
      },
      "source": [
        "# 環境設定"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KilzP2OvLxi6",
        "outputId": "6298da67-4b90-4144-ec58-376da9775d83"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting selenium\n",
            "  Downloading selenium-4.1.0-py3-none-any.whl (958 kB)\n",
            "\u001b[K     |████████████████████████████████| 958 kB 5.2 MB/s \n",
            "\u001b[?25hCollecting urllib3[secure]~=1.26\n",
            "  Downloading urllib3-1.26.7-py2.py3-none-any.whl (138 kB)\n",
            "\u001b[K     |████████████████████████████████| 138 kB 51.6 MB/s \n",
            "\u001b[?25hCollecting trio-websocket~=0.9\n",
            "  Downloading trio_websocket-0.9.2-py3-none-any.whl (16 kB)\n",
            "Collecting trio~=0.17\n",
            "  Downloading trio-0.19.0-py3-none-any.whl (356 kB)\n",
            "\u001b[K     |████████████████████████████████| 356 kB 46.3 MB/s \n",
            "\u001b[?25hCollecting outcome\n",
            "  Downloading outcome-1.1.0-py2.py3-none-any.whl (9.7 kB)\n",
            "Requirement already satisfied: sortedcontainers in /usr/local/lib/python3.7/dist-packages (from trio~=0.17->selenium) (2.4.0)\n",
            "Requirement already satisfied: attrs>=19.2.0 in /usr/local/lib/python3.7/dist-packages (from trio~=0.17->selenium) (21.2.0)\n",
            "Collecting sniffio\n",
            "  Downloading sniffio-1.2.0-py3-none-any.whl (10 kB)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.7/dist-packages (from trio~=0.17->selenium) (2.10)\n",
            "Collecting async-generator>=1.9\n",
            "  Downloading async_generator-1.10-py3-none-any.whl (18 kB)\n",
            "Collecting wsproto>=0.14\n",
            "  Downloading wsproto-1.0.0-py3-none-any.whl (24 kB)\n",
            "Collecting pyOpenSSL>=0.14\n",
            "  Downloading pyOpenSSL-21.0.0-py2.py3-none-any.whl (55 kB)\n",
            "\u001b[K     |████████████████████████████████| 55 kB 2.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from urllib3[secure]~=1.26->selenium) (2021.10.8)\n",
            "Collecting cryptography>=1.3.4\n",
            "  Downloading cryptography-36.0.1-cp36-abi3-manylinux_2_24_x86_64.whl (3.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.6 MB 47.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.7/dist-packages (from cryptography>=1.3.4->urllib3[secure]~=1.26->selenium) (1.15.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.12->cryptography>=1.3.4->urllib3[secure]~=1.26->selenium) (2.21)\n",
            "Requirement already satisfied: six>=1.5.2 in /usr/local/lib/python3.7/dist-packages (from pyOpenSSL>=0.14->urllib3[secure]~=1.26->selenium) (1.15.0)\n",
            "Collecting h11<1,>=0.9.0\n",
            "  Downloading h11-0.12.0-py3-none-any.whl (54 kB)\n",
            "\u001b[K     |████████████████████████████████| 54 kB 2.8 MB/s \n",
            "\u001b[?25hInstalling collected packages: sniffio, outcome, h11, cryptography, async-generator, wsproto, urllib3, trio, pyOpenSSL, trio-websocket, selenium\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.24.3\n",
            "    Uninstalling urllib3-1.24.3:\n",
            "      Successfully uninstalled urllib3-1.24.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "requests 2.23.0 requires urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1, but you have urllib3 1.26.7 which is incompatible.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "Successfully installed async-generator-1.10 cryptography-36.0.1 h11-0.12.0 outcome-1.1.0 pyOpenSSL-21.0.0 selenium-4.1.0 sniffio-1.2.0 trio-0.19.0 trio-websocket-0.9.2 urllib3-1.26.7 wsproto-1.0.0\n",
            "Get:1 http://security.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB]\n",
            "Ign:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n",
            "Get:3 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease [3,626 B]\n",
            "Get:4 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease [15.9 kB]\n",
            "Ign:5 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
            "Hit:6 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
            "Get:7 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release [696 B]\n",
            "Hit:8 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
            "Get:9 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release.gpg [836 B]\n",
            "Get:10 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB]\n",
            "Hit:11 http://ppa.launchpad.net/cran/libgit2/ubuntu bionic InRelease\n",
            "Get:12 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [74.6 kB]\n",
            "Get:13 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic InRelease [15.9 kB]\n",
            "Get:14 http://security.ubuntu.com/ubuntu bionic-security/restricted amd64 Packages [691 kB]\n",
            "Get:15 http://security.ubuntu.com/ubuntu bionic-security/universe amd64 Packages [1,452 kB]\n",
            "Hit:16 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n",
            "Get:17 http://security.ubuntu.com/ubuntu bionic-security/main amd64 Packages [2,461 kB]\n",
            "Get:18 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ Packages [73.9 kB]\n",
            "Get:20 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Packages [833 kB]\n",
            "Get:21 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic/main Sources [1,822 kB]\n",
            "Get:22 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic/main amd64 Packages [934 kB]\n",
            "Get:23 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 Packages [2,230 kB]\n",
            "Get:24 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic/main amd64 Packages [45.3 kB]\n",
            "Get:25 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 Packages [2,898 kB]\n",
            "Get:26 http://archive.ubuntu.com/ubuntu bionic-backports/main amd64 Packages [11.6 kB]\n",
            "Get:27 http://archive.ubuntu.com/ubuntu bionic-backports/universe amd64 Packages [12.6 kB]\n",
            "Fetched 13.8 MB in 7s (1,970 kB/s)\n",
            "Reading package lists... Done\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  chromium-browser chromium-browser-l10n chromium-codecs-ffmpeg-extra\n",
            "Suggested packages:\n",
            "  webaccounts-chromium-extension unity-chromium-extension\n",
            "The following NEW packages will be installed:\n",
            "  chromium-browser chromium-browser-l10n chromium-chromedriver\n",
            "  chromium-codecs-ffmpeg-extra\n",
            "0 upgraded, 4 newly installed, 0 to remove and 85 not upgraded.\n",
            "Need to get 94.0 MB of archives.\n",
            "After this operation, 324 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 chromium-codecs-ffmpeg-extra amd64 95.0.4638.69-0ubuntu0.18.04.1 [1,135 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 chromium-browser amd64 95.0.4638.69-0ubuntu0.18.04.1 [83.6 MB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 chromium-browser-l10n all 95.0.4638.69-0ubuntu0.18.04.1 [4,249 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 chromium-chromedriver amd64 95.0.4638.69-0ubuntu0.18.04.1 [4,986 kB]\n",
            "Fetched 94.0 MB in 4s (23.7 MB/s)\n",
            "Selecting previously unselected package chromium-codecs-ffmpeg-extra.\n",
            "(Reading database ... 155222 files and directories currently installed.)\n",
            "Preparing to unpack .../chromium-codecs-ffmpeg-extra_95.0.4638.69-0ubuntu0.18.04.1_amd64.deb ...\n",
            "Unpacking chromium-codecs-ffmpeg-extra (95.0.4638.69-0ubuntu0.18.04.1) ...\n",
            "Selecting previously unselected package chromium-browser.\n",
            "Preparing to unpack .../chromium-browser_95.0.4638.69-0ubuntu0.18.04.1_amd64.deb ...\n",
            "Unpacking chromium-browser (95.0.4638.69-0ubuntu0.18.04.1) ...\n",
            "Selecting previously unselected package chromium-browser-l10n.\n",
            "Preparing to unpack .../chromium-browser-l10n_95.0.4638.69-0ubuntu0.18.04.1_all.deb ...\n",
            "Unpacking chromium-browser-l10n (95.0.4638.69-0ubuntu0.18.04.1) ...\n",
            "Selecting previously unselected package chromium-chromedriver.\n",
            "Preparing to unpack .../chromium-chromedriver_95.0.4638.69-0ubuntu0.18.04.1_amd64.deb ...\n",
            "Unpacking chromium-chromedriver (95.0.4638.69-0ubuntu0.18.04.1) ...\n",
            "Setting up chromium-codecs-ffmpeg-extra (95.0.4638.69-0ubuntu0.18.04.1) ...\n",
            "Setting up chromium-browser (95.0.4638.69-0ubuntu0.18.04.1) ...\n",
            "update-alternatives: using /usr/bin/chromium-browser to provide /usr/bin/x-www-browser (x-www-browser) in auto mode\n",
            "update-alternatives: using /usr/bin/chromium-browser to provide /usr/bin/gnome-www-browser (gnome-www-browser) in auto mode\n",
            "Setting up chromium-chromedriver (95.0.4638.69-0ubuntu0.18.04.1) ...\n",
            "Setting up chromium-browser-l10n (95.0.4638.69-0ubuntu0.18.04.1) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "Processing triggers for hicolor-icon-theme (0.17-2) ...\n",
            "Processing triggers for mime-support (3.60ubuntu1) ...\n",
            "Processing triggers for libc-bin (2.27-3ubuntu1.3) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/python3.7/dist-packages/ideep4py/lib/libmkldnn.so.0 is not a symbolic link\n",
            "\n",
            "cp: '/usr/lib/chromium-browser/chromedriver' and '/usr/bin/chromedriver' are the same file\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  tesseract-ocr-eng tesseract-ocr-osd\n",
            "The following NEW packages will be installed:\n",
            "  tesseract-ocr tesseract-ocr-eng tesseract-ocr-osd\n",
            "0 upgraded, 3 newly installed, 0 to remove and 85 not upgraded.\n",
            "Need to get 4,795 kB of archives.\n",
            "After this operation, 15.8 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic/universe amd64 tesseract-ocr-eng all 4.00~git24-0e00fe6-1.2 [1,588 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu bionic/universe amd64 tesseract-ocr-osd all 4.00~git24-0e00fe6-1.2 [2,989 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu bionic/universe amd64 tesseract-ocr amd64 4.00~git2288-10f4998a-2 [218 kB]\n",
            "Fetched 4,795 kB in 1s (4,343 kB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76, <> line 3.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package tesseract-ocr-eng.\n",
            "(Reading database ... 155589 files and directories currently installed.)\n",
            "Preparing to unpack .../tesseract-ocr-eng_4.00~git24-0e00fe6-1.2_all.deb ...\n",
            "Unpacking tesseract-ocr-eng (4.00~git24-0e00fe6-1.2) ...\n",
            "Selecting previously unselected package tesseract-ocr-osd.\n",
            "Preparing to unpack .../tesseract-ocr-osd_4.00~git24-0e00fe6-1.2_all.deb ...\n",
            "Unpacking tesseract-ocr-osd (4.00~git24-0e00fe6-1.2) ...\n",
            "Selecting previously unselected package tesseract-ocr.\n",
            "Preparing to unpack .../tesseract-ocr_4.00~git2288-10f4998a-2_amd64.deb ...\n",
            "Unpacking tesseract-ocr (4.00~git2288-10f4998a-2) ...\n",
            "Setting up tesseract-ocr-osd (4.00~git24-0e00fe6-1.2) ...\n",
            "Setting up tesseract-ocr-eng (4.00~git24-0e00fe6-1.2) ...\n",
            "Setting up tesseract-ocr (4.00~git2288-10f4998a-2) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "Collecting pytesseract\n",
            "  Downloading pytesseract-0.3.8.tar.gz (14 kB)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from pytesseract) (7.1.2)\n",
            "Building wheels for collected packages: pytesseract\n",
            "  Building wheel for pytesseract (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pytesseract: filename=pytesseract-0.3.8-py2.py3-none-any.whl size=14072 sha256=66e3737632d0f32450e14d9c314167ad48320341d082f50dd2ff9852fbb9fa07\n",
            "  Stored in directory: /root/.cache/pip/wheels/a4/89/b9/3f11250225d0f90e5454fcc30fd1b7208db226850715aa9ace\n",
            "Successfully built pytesseract\n",
            "Installing collected packages: pytesseract\n",
            "Successfully installed pytesseract-0.3.8\n"
          ]
        }
      ],
      "source": [
        "#環境設定\n",
        "!pip install selenium\n",
        "!apt-get update # to update ubuntu to correctly run apt install\n",
        "!apt install chromium-chromedriver\n",
        "!cp /usr/lib/chromium-browser/chromedriver /usr/bin\n",
        "\n",
        "#wget https://chromedriver.storage.googleapis.com/96.0.4664.45/chromedriver_linux64.zip\n",
        "#!unzip /content/colab/chromedriver_linux64.zip\n",
        "#!cp /content/colab/chromedriver /usr/lib\n",
        "#!cp /content/colab/chromedriver /usr/bin\n",
        "\n",
        "#sys.path.insert(0,'/usr/bin/chromedriver')\n",
        "!sudo apt install tesseract-ocr\n",
        "!pip install pytesseract"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HKsMQGWRawkA"
      },
      "source": [
        "# 共通程式"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "El7P4xda0opS"
      },
      "outputs": [],
      "source": [
        "# Line Notify\n",
        "def Line(msg,path_pic=None):\n",
        "    import requests\n",
        "    global tokenDropbox\n",
        "    tokenLine = 'apfSt2nGRwzBuCuFWtH9qRCX8BGATHEyCiBAIQzAwup'\n",
        "\n",
        "    headers = {\n",
        "        \"Authorization\": \"Bearer \" + tokenLine\n",
        "    }\n",
        "    payload = {'message': msg}\n",
        "    if path_pic!=None:\n",
        "      files = {'imageFile':open(path_pic,'rb')}\n",
        "      r = requests.post(\"https://notify-api.line.me/api/notify\", headers = headers, params = payload,files=files)\n",
        "    else:\n",
        "      r = requests.post(\"https://notify-api.line.me/api/notify\", headers = headers, params = payload)\n",
        "    return r.status_code\n",
        "\n",
        "def SendFileToDropbox(fileLocal,fileDropbox):\n",
        "    ##### upload file to dropbox #####\n",
        "\n",
        "    try:\n",
        "        import dropbox\n",
        "        #print(\"module is installed\")\n",
        "    except ModuleNotFoundError:\n",
        "        print(\"module is not installed\")\n",
        "        # or\n",
        "        !pip install dropbox\n",
        "        import dropbox\n",
        "\n",
        "    from dropbox.files import WriteMode\n",
        "    from dropbox.exceptions import ApiError, AuthError\n",
        "    global tokenDropbox\n",
        "    tokenDropbox = \"9VjbJCirSqsAAAAAAAA1JuBzv7mujcQGbebgTGu2IjDup-N77QjVY8MEsg1ccizx\"\n",
        "    dbx = dropbox.Dropbox(tokenDropbox)\n",
        "    with open(fileLocal, 'rb') as f:\n",
        "      dbx.files_upload(f.read(), \"/\"+fileDropbox, mode=WriteMode('overwrite')) \n",
        "      f.close()\n",
        "\n",
        "\n",
        "def GetFileFromDropbox(fileDropbox,fileLocal):\n",
        "    ##### download file frome dropbox #####\n",
        "    try:\n",
        "        import dropbox\n",
        "        #print(\"module is installed\")\n",
        "    except ModuleNotFoundError:\n",
        "        print(\"module is not installed\")\n",
        "        # or\n",
        "        !pip install dropbox\n",
        "        import dropbox\n",
        "\n",
        "    from dropbox.files import WriteMode\n",
        "    from dropbox.exceptions import ApiError, AuthError\n",
        "    global tokenDropbox\n",
        "    tokenDropbox = \"9VjbJCirSqsAAAAAAAA1JuBzv7mujcQGbebgTGu2IjDup-N77QjVY8MEsg1ccizx\"\n",
        "    dbx = dropbox.Dropbox(tokenDropbox)\n",
        "    with open(fileLocal, \"wb\") as f:\n",
        "      metadata, res = dbx.files_download(\"/\"+fileDropbox)\n",
        "      f.write(res.content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "7y5M_W7GpoW9"
      },
      "outputs": [],
      "source": [
        "#設定\n",
        "import sys\n",
        "import os\n",
        "import base64 \n",
        "import datetime\n",
        "import time\n",
        "import json\n",
        "import pandas as pd\n",
        "\n",
        "from datetime import datetime,timedelta\n",
        "from pathlib import Path \n",
        "from urllib.parse import urlparse\n",
        "from selenium import webdriver\n",
        "from selenium.common.exceptions import NoSuchElementException\n",
        "\n",
        "#global\n",
        "#global tokenDropbox,tokenLine\n",
        "#tokenDropbox = \"9VjbJCirSqsAAAAAAAA1JuBzv7mujcQGbebgTGu2IjDup-N77QjVY8MEsg1ccizx\"\n",
        "#tokenLine = 'apfSt2nGRwzBuCuFWtH9qRCX8BGATHEyCiBAIQzAwup'\n",
        "\n",
        "#設定Selenium\n",
        "options = webdriver.ChromeOptions()\n",
        "options.add_argument('--headless')\n",
        "options.add_argument('--no-sandbox')\n",
        "options.add_argument('--disable-dev-shm-usage')\n",
        "\n",
        "prjName = \"OCR_Img_twse_bsr\"\n",
        "\n",
        "headLess = True\n",
        "\n",
        "Path(prjName).mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# 如要使用Chrome瀏覽器，需使用相對應版本的ChromeDriver\n",
        "# Src: https://chromedriver.chromium.org/\n",
        "wdPath = '/usr/lib/chromium-browser/chromedriver'\n",
        "#wdPath = '/usr/lib/chromedriver'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sYPVWX_vbEz5"
      },
      "source": [
        "# 函數:Stock"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6RfYQBiuTKvw",
        "outputId": "897df437-4bcd-4254-ff0f-7badd7a9c403"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======  20211227  ======\n"
          ]
        }
      ],
      "source": [
        "def StartdayParseStock():\n",
        "  from datetime import datetime, timedelta\n",
        "  if (datetime.now()+timedelta(hours=8)).strftime(\"%H%M%S\")<\"160000\":\n",
        "    date   = (datetime.now()+timedelta(hours=8)+timedelta(days=-1)).strftime(\"%Y%m%d\")  \n",
        "  else:\n",
        "    date   = (datetime.now()+timedelta(hours=8)).strftime(\"%Y%m%d\")\n",
        "  return date\n",
        "\n",
        "global dateStartday\n",
        "dateStartday =  StartdayParseStock()\n",
        "print(\"======  \" +  dateStartday  + \"  ======\"  )\n",
        "#dateStartday=\"20210514\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "jla9Yp8CTk7r"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "jztK3Iam9SAL"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "h4XomNj-AtGY"
      },
      "outputs": [],
      "source": [
        "def ParseBioCSV(stock):\n",
        "  print('chromedriver is lunching..')\n",
        "  wd = webdriver.Chrome(options=options)\n",
        "  #time.sleep(1)\n",
        "  print('chromedriver is ready..')\n",
        "\n",
        "  #抓取captcha\n",
        "  urlString = \"https://bsr.twse.com.tw/bshtm/bsMenu.aspx\"\n",
        "  parsed_uri = urlparse(urlString)\n",
        "  # from urlparse import urlparse  # Python 2\n",
        "  #result = '{uri.scheme}://{uri.netloc}/'.format(uri=parsed_uri)\n",
        "  sitePath = '{uri.hostname}'.format(uri=parsed_uri)\n",
        "\n",
        "  imgPath = prjName + \"\\\\\" + sitePath\n",
        "  Path(imgPath).mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "  print('get web page....Start')\n",
        "  wd.get(urlString)\n",
        "  #time.sleep(1)\n",
        "  print('get web page....Done')\n",
        "\n",
        "  def get_captcha_img(): # return saved file's name\n",
        "      # 此網站的動態驗證碼是存放在 tag img\n",
        "      #target_img = wd.find_element_by_id(\"authPic\")\n",
        "      target_img = wd.find_element_by_css_selector(\"#Panel_bshtm img\")\n",
        "      \n",
        "      # get the canvas as a PNG base64 string\n",
        "      img_base64 = wd.execute_script(\"x=arguments[0];c=document.createElement('canvas');c.width=x.width,c.height=x.height;t=c.getContext('2d');t.drawImage(x, 0, 0);return c.toDataURL('image/png').substring(21);\", target_img)\n",
        "      \n",
        "      # decode\n",
        "      img_png = base64.b64decode(img_base64)\n",
        "      \n",
        "      # save to a file\n",
        "      dtNow = datetime.now()\n",
        "      \n",
        "      fileName = '{}\\\\{}{}{}_{}{}{}.png'\n",
        "      fileName = fileName.format(imgPath, dtNow.strftime(\"%Y\"), dtNow.strftime(\"%m\"), dtNow.strftime(\"%d\"), dtNow.strftime(\"%H\"), dtNow.strftime(\"%M\"), dtNow.strftime(\"%S\"))\n",
        "      with open(fileName, 'wb') as f:\n",
        "          f.write(img_png)\n",
        "      return fileName\n",
        "\n",
        "  fileName=get_captcha_img()\n",
        "\n",
        "  print('png saved')\n",
        "\n",
        "  #OCR\n",
        "  # 載入圖形相關函式\n",
        "\n",
        "  try:\n",
        "      from PIL import Image\n",
        "  except ImportError:\n",
        "      import Image\n",
        "  import PIL.ImageOps \n",
        "  import pytesseract\n",
        "\n",
        "  from IPython.display import display\n",
        "\n",
        "  def convert_img1(img, threshold): # 先灰階，轉補色，再黑白處理\n",
        "      img = img.convert(\"L\")  # 轉為灰階\n",
        "      img = PIL.ImageOps.invert(img)\n",
        "      pixels = img.load()\n",
        "      for x in range(img.width):\n",
        "          for y in range(img.height):\n",
        "              if pixels[x, y] > threshold:\n",
        "                  pixels[x, y] = 255\n",
        "              else:\n",
        "                  pixels[x, y] = 0\n",
        "      return img\n",
        "\n",
        "  # 8鄰域降燥辨識\n",
        "  def noise_remove_pil(img, ctrlG, ctrlK): # 8鄰域降噪, ctrlG:小餘折是非白, ctrlK:小於ctrlK個非白點就轉白\n",
        "      def calculate_noise_count(img_obj, w, h): # 計算鄰域非白色的個數\n",
        "          count = 0\n",
        "          width, height = img_obj.size\n",
        "          for _w_ in [w - 1, w, w + 1]:\n",
        "              for _h_ in [h - 1, h, h + 1]:\n",
        "                  if _w_ > width - 1:\n",
        "                      continue\n",
        "                  if _h_ > height - 1:\n",
        "                      continue\n",
        "                  if _w_ == w and _h_ == h:\n",
        "                      continue\n",
        "                  if img_obj.getpixel((_w_, _h_)) < ctrlG:  # 這裡因為是灰度影像，設定小於230為非白色\n",
        "                      count += 1\n",
        "          return count\n",
        "\n",
        "      img = img.convert(\"L\")\n",
        "      img = PIL.ImageOps.invert(img)\n",
        "      w, h = img.size\n",
        "      \n",
        "      for _w in range(w):\n",
        "          for _h in range(h):\n",
        "              if _w == 0 or _h == 0:\n",
        "                  img.putpixel((_w, _h), 255)\n",
        "                  continue\n",
        "              pixel = img.getpixel((_w, _h))\n",
        "              if pixel == 255:\n",
        "                  continue\n",
        "\n",
        "              # 計算鄰域非白色的個數\n",
        "              if calculate_noise_count(img, _w, _h) < ctrlK:\n",
        "                  img.putpixel((_w, _h), 255)\n",
        "      return img\n",
        "\n",
        "  captcha4 = Image.open(fileName)\n",
        "  captcha4 = noise_remove_pil(captcha4, 10, 4)\n",
        "\n",
        "  result4 = pytesseract.image_to_string(captcha4)\n",
        "  print(result4)\n",
        "  #display(captcha4)\n",
        "\n",
        "  # 二值化降噪辨識，又稱8鄰域降燥，灰階圖辨識與轉黑白後辨識有的時候會不同效益\n",
        "  def depointImg(img, ctrlV, ctrlK): # 二值化降噪辨識，大於ctrlV是為白點，超過ctrlK個白點轉白\n",
        "      img = img.convert(\"L\")\n",
        "      img = PIL.ImageOps.invert(img)\n",
        "      pixels = img.load()\n",
        "      w, h = img.size\n",
        "      for y in range(1, h - 1):\n",
        "          for x in range(1, w - 1):\n",
        "              count = 0\n",
        "              if pixels[x - 1, y - 1] > ctrlV:  # 左上\n",
        "                  count = count + 1\n",
        "              if pixels[x,     y - 1] > ctrlV:  # 上\n",
        "                  count = count + 1\n",
        "              if pixels[x + 1, y - 1] > ctrlV:  # 右上\n",
        "                  count = count + 1\n",
        "                  \n",
        "              if pixels[x - 1, y] > ctrlV:  # 左\n",
        "                  count = count + 1\n",
        "              if pixels[x + 1, y] > ctrlV:  # 右\n",
        "                  count = count + 1\n",
        "\n",
        "              if pixels[x - 1, y + 1] > ctrlV:  # 左下\n",
        "                  count = count + 1\n",
        "              if pixels[x,     y + 1] > ctrlV:  # 下\n",
        "                  count = count + 1\n",
        "              if pixels[x + 1, y + 1] > ctrlV:  # 右下\n",
        "                  count = count + 1\n",
        "                  \n",
        "              if count > ctrlK:\n",
        "                  pixels[x, y] = 255\n",
        "      return img\n",
        "\n",
        "\n",
        "  captcha5 = Image.open(fileName)\n",
        "  captcha5 = depointImg(captcha5, 10, 4)\n",
        "\n",
        "  result5 = pytesseract.image_to_string(captcha5)\n",
        "  print(result5)\n",
        "  #display(captcha5)\n",
        "\n",
        "  result4 = result4.replace(' ', '').strip()\n",
        "  result5 = result5.replace(' ', '').strip()\n",
        "  print('r4=' + result4)\n",
        "  print('r5=' + result5)\n",
        "  display(captcha4)\n",
        "  display(captcha5)\n",
        "  captchaCode=''\n",
        "\n",
        "  if len(result5)==5:\n",
        "      captchaCode=result5\n",
        "      print('captcha5 identified!!')\n",
        "  elif len(result4)==5:\n",
        "      captchaCode=result4\n",
        "      print('captcha4 identified!!')\n",
        "  else:\n",
        "      print('captcha identify failled!')\n",
        "      parseSuccess = \"No\"\n",
        "\n",
        "  if len(captchaCode)==5:\n",
        "      txtStkCode = wd.find_elements(By.ID,\"TextBox_Stkno\")\n",
        "      txtStkCode.send_keys(stock)\n",
        "    \n",
        "      txtCaptcha = wd.find_elements(By.NAME,\"CaptchaControl1\")\n",
        "      txtCaptcha.send_keys(captchaCode)\n",
        "      btnOK = wd.find_elements(By.ID,\"btnOK\")\n",
        "      btnOK.click()\n",
        "      try:\n",
        "          dd = wd.find_elements(By.ID,\"HyperLink_DownloadCSV\") \n",
        "          dd.click()\n",
        "          print('file downloading...')\n",
        "          sleep(5)\n",
        "          while not os.path.exists(stock + \".csv\"):\n",
        "            sleep(2)\n",
        "            print(\"file downloading..wait\")    \n",
        "          parseSuccess = \"Yes\"\n",
        "      except NoSuchElementException:\n",
        "          print('captcha code error!')\n",
        "          parseSuccess = \"No\"\n",
        "\n",
        "  print('chromedriver closing..')\n",
        "  wd.quit()\n",
        "  print('chromedriver closed..')\n",
        "  \n",
        "  return parseSuccess  \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qdEZkr61bgXW"
      },
      "source": [
        "# 主程式:StockBio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "aHtjp4xZPqM_"
      },
      "outputs": [],
      "source": [
        "def GetProgressFromDropbox(machine):\n",
        "  import pandas as pd\n",
        "  fileProgress = \"bio\\\\\"+str(dateStartday)+\"\\\\\"+\"bio_progress\"+str(machine)+\".csv\" \n",
        "  GetFileFromDropbox(\"bio/\"+str(dateStartday)+\"/\"+\"bio_progress\"+str(machine)+\".csv\",\"\\\\\"+fileProgress )\n",
        "  loopsDropbox = pd.read_csv(\"\\\\\"+fileProgress, names=[\"col\"],header=None, dtype = str).col.tolist()\n",
        "  return loopsDropbox\n",
        "\n",
        "def SendProgressToDropbox(nowProgress,machine):\n",
        "  import pandas as pd\n",
        "  fileProgress = \"bio\\\\\"+str(dateStartday)+\"\\\\\"+\"bio_progress\" + str(machine) + \".csv\" \n",
        "  pd.DataFrame(nowProgress).to_csv(\"\\\\\"+fileProgress,index= False,header=False)\n",
        "  SendFileToDropbox(\"\\\\\"+fileProgress,\"bio/\"+str(dateStartday)+\"/\"+\"bio_progress\"+str(machine)+\".csv\")\n",
        "  print(\"Send Progress\"+ str(machine)+ \" to Dropbox ..\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "1CHSLbsEYNcO"
      },
      "outputs": [],
      "source": [
        "#print(\"====  \"+ \"Remain:\" +str(len(GetProgressFromDropbox())) + \"jobs\" + \"  =====\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "vdRKIGOKa4D4"
      },
      "outputs": [],
      "source": [
        "def DynamicLoopsParseBioCSV(machine):\n",
        "    from pathlib import Path \n",
        "\n",
        "    bioPath = \"bio\" + \"\\\\\" + str(dateStartday)\n",
        "    Path(bioPath).mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    try:\n",
        "      loopsDropbox = GetProgressFromDropbox(machine)\n",
        "      print(\"get bio progress from dropbox ..\")\n",
        "    except:\n",
        "      print('error:get bio progress from dropbox ..')\n",
        "      loopsDropbox = []\n",
        "\n",
        "    if len(loopsDropbox)==0:\n",
        "      print(\"new progress ..\")\n",
        "      if \"jf\" not in locals() and \"jf\" not in globals():\n",
        "        jf  = ParseTWSE_OHLC(dateStartday)\n",
        "      loops = LoopsTWSE_OHLC(jf)\n",
        "    else:\n",
        "      print(\"continue progress ..\")\n",
        "      loops = loopsDropbox\n",
        "    \n",
        "    return loops,loopsDropbox"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "nvfn39_fviol"
      },
      "outputs": [],
      "source": [
        "def ExecuteLoopsBio(loops):\n",
        "  Line( str(machine)+\": start\")\n",
        "  for stock in loops:\n",
        "    #line to notify\n",
        "    #Line( str(machine)+\":\"+str(stock)+\",Remain:\"+str(len(loops)) )\n",
        "    \n",
        "    #use selenium to download file\n",
        "    parseSuccess=\"No\"\n",
        "    while parseSuccess==\"No\":\n",
        "      print(\"====  \"+str(stock)+\" parsing .. \"+\"  ====\")\n",
        "      parseSuccess = ParseBioCSV(stock)\n",
        "      sleep(randint(5,7))\n",
        "      clear_output(wait=True)\n",
        "      \n",
        "    #rename file and send to dropbox \n",
        "    if parseSuccess == \"Yes\":\n",
        "      #Rename file\n",
        "      timestamp = (datetime.now()+timedelta(hours=8)).strftime(\"%Y%m%d_%H%M%S\")\n",
        "      boxfile   = str(stock)+\"_\"+timestamp+\".csv\"\n",
        "      os.rename(str(stock)+\".csv\",boxfile)\n",
        "      print('renameCSV closed..')\n",
        "\n",
        "      #send bio to Dropbox\n",
        "      SendFileToDropbox(boxfile, \"bio/\"+dateStartday +\"/\"+ boxfile)\n",
        "      print('csv to dropbox closed..')\n",
        "\n",
        "      #send progress to Dropbox\n",
        "      loops = loops[1:len(loops)]\n",
        "      SendProgressToDropbox(loops,machine)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 215
        },
        "id": "0-5mgAMcxXfC",
        "outputId": "5b6f503f-1488-4edb-f49d-bf7216130008"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-bbe3b34b59d7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mwd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwebdriver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mChrome\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mloops\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mloopsDropbox\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDynamicLoopsParseBioCSV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmachine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mExecuteLoopsBio\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloops\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'machine' is not defined"
          ]
        }
      ],
      "source": [
        "from time import sleep\n",
        "from random import randint\n",
        "from IPython.display import clear_output\n",
        "\n",
        "wd = webdriver.Chrome(options=options)\n",
        "loops,loopsDropbox = DynamicLoopsParseBioCSV(machine)\n",
        "ExecuteLoopsBio(loops)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7VZJ04anP1Ld"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "JobsBioParse2.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}